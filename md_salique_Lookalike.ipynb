{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Combine data\n",
    "data = transactions.merge(customers, on=\"CustomerID\").merge(products, on=\"ProductID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total spending per customer\n",
    "total_spending = data.groupby(\"CustomerID\")[\"TotalValue\"].sum().rename(\"TotalSpending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of transactions per customer\n",
    "transaction_count = data.groupby(\"CustomerID\")[\"TransactionID\"].nunique().rename(\"TransactionCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular product category per customer\n",
    "popular_category = data.groupby([\"CustomerID\", \"Category\"])[\"Quantity\"].sum().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region encoding\n",
    "region_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "region_encoded = pd.DataFrame(\n",
    "    region_encoder.fit_transform(customers[[\"Region\"]]),\n",
    "    index=customers[\"CustomerID\"],\n",
    "    columns=region_encoder.get_feature_names_out([\"Region\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into a single DataFrame\n",
    "customer_features = pd.concat([total_spending, transaction_count, popular_category, region_encoded], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(customer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different LookAlike models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for Cosine Similarity: 0.4400647765397279\n",
      "Silhouette Score for Euclidean Similarity: 0.0927872489133819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for Manhattan Similarity: 0.06782067957500837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "\n",
    "# 1. Cosine Similarity\n",
    "cosine_sim_matrix = cosine_similarity(normalized_features)\n",
    "\n",
    "# 2. Euclidean Distance (convert to similarity by inverting distances)\n",
    "euclidean_dist_matrix = euclidean_distances(normalized_features)\n",
    "euclidean_sim_matrix = 1 / (1 + euclidean_dist_matrix)  # Adding 1 to avoid division by zero\n",
    "\n",
    "# 3. Manhattan Distance (convert to similarity)\n",
    "manhattan_dist_matrix = manhattan_distances(normalized_features)\n",
    "manhattan_sim_matrix = 1 / (1 + manhattan_dist_matrix)\n",
    "\n",
    "# Clustering and Validation\n",
    "similarity_matrices = {\n",
    "    \"Cosine Similarity\": cosine_sim_matrix,\n",
    "    \"Euclidean Similarity\": euclidean_sim_matrix,\n",
    "    \"Manhattan Similarity\": manhattan_sim_matrix\n",
    "}\n",
    "\n",
    "# Number of clusters for validation \n",
    "num_clusters = 5\n",
    "cluster_validation_scores = {}\n",
    "\n",
    "# Function to set the diagonal of a matrix to zero\n",
    "def zero_diagonal(matrix):\n",
    "    np.fill_diagonal(matrix, 0)\n",
    "    return matrix\n",
    "\n",
    "def similarity_to_distance(matrix):\n",
    "    return 1 - matrix\n",
    "\n",
    "# Validation Loop\n",
    "for sim_name, sim_matrix in similarity_matrices.items():\n",
    "    # Convert similarity to distance\n",
    "    sim_matrix_no_diag = similarity_to_distance(sim_matrix.copy())\n",
    "    np.fill_diagonal(sim_matrix_no_diag, 0)  # diagonal is zero\n",
    "    \n",
    "    # Use KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(sim_matrix_no_diag)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(sim_matrix_no_diag, cluster_labels, metric=\"precomputed\")\n",
    "    cluster_validation_scores[sim_name] = silhouette_avg\n",
    "    print(f\"Silhouette Score for {sim_name}: {silhouette_avg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Similarity Method based on Silhouette Score: Cosine Similarity\n"
     ]
    }
   ],
   "source": [
    "best_method = max(cluster_validation_scores, key=cluster_validation_scores.get)\n",
    "print(f\"\\nBest Similarity Method based on Silhouette Score: {best_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity works best, using that as Lookalike Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike.csv has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity scores\n",
    "similarity_matrix = cosine_similarity(normalized_features)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features.index, columns=customer_features.index)\n",
    "\n",
    "# Generate Lookalike Recommendations\n",
    "lookalike_results = {}\n",
    "for cust_id in customers[\"CustomerID\"][:20]:  # First 20 customers\n",
    "    similar_customers = similarity_df[cust_id].drop(cust_id).sort_values(ascending=False).head(3)\n",
    "    lookalike_results[cust_id] = [(other_cust, round(score, 2)) for other_cust, score in similar_customers.items()]\n",
    "\n",
    "# Save the results as Lookalike.csv\n",
    "lookalike_df = pd.DataFrame({\n",
    "    \"CustomerID\": lookalike_results.keys(),\n",
    "    \"Lookalikes\": [str(lookalike_results[cust_id]) for cust_id in lookalike_results.keys()]\n",
    "})\n",
    "lookalike_df.to_csv(\"Lookalike.csv\", index=False)\n",
    "\n",
    "print(\"Lookalike.csv has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
